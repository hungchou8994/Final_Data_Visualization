import os
import streamlit as st
import pandas as pd
from openai import OpenAI as oai
from pandasai import SmartDataframe
from pandasai.llm import OpenAI
from pandasai.responses.response_parser import ResponseParser

def load_file_content(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            return file.read().strip()
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file {file_path}: {e}")
        return ""

# Load dataset-related information
dataset_text = load_file_content("./data/dataset_info.txt")
extra_info = load_file_content("./data/extra_info.txt")
extra_info_2 = load_file_content("./data/extra_info_2.txt")
#density = load_file_content("./data/density.txt")
openai_insights = load_file_content("./data/openai_insights.txt")
#openai_insights_2 = load_file_content("./data/openai_insights_2.txt")
openai_summary = load_file_content("./data/openai_summary.txt")


class StreamlitResponse(ResponseParser):
    def __init__(self, context) -> None:
        super().__init__(context)

    def format_dataframe(self, result):
        st.dataframe(result["value"])
        return

    def format_plot(self, result):
        st.image(result["value"])
        return

    def format_other(self, result):
        st.write(result["value"])
        return

df = pd.read_csv('./data/data_dv.csv', encoding="utf-8")

st.write("Tr·ª£ l√Ω AI b√°o c√°o d·ªØ li·ªáu")

with st.expander("üîé Dataframe Preview"):
    st.write(df.tail(3))

from dotenv import load_dotenv
load_dotenv()

OPENAI_API_KEY= os.getenv("OPENAI_API_KEY")

llm = OpenAI(api_token=OPENAI_API_KEY)

query = st.text_area("üó£Ô∏è Chat with Dataframe")

client = oai(
    api_key=OPENAI_API_KEY,
)

def generate_openai_response(prompt, model="gpt-4o-mini", max_tokens=1500):
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh, c√≥ kh·∫£ nƒÉng tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn m·ªôt b·ªô d·ªØ li·ªáu l·ªõn."},
                {"role": "user", "content": prompt}
            ],
            #max_tokens=max_tokens,
            temperature=0.7,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"L·ªói khi g·ªçi API OpenAI: {e}"

def process_user_query(query, openai_answer):
    system_prompt = (
        f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh v·ªõi kh·∫£ nƒÉng tr·∫£ l·ªùi c√°c c√¢u h·ªèi ph·ª©c t·∫°p li√™n quan ƒë·∫øn b·ªô d·ªØ li·ªáu l·ªõn v√† ph√¢n t√≠ch s√¢u s·∫Øc. B·∫°n c√≥ kh·∫£ nƒÉng gi√∫p ng∆∞·ªùi d√πng hi·ªÉu r√µ h∆°n v·ªÅ c√°c th√¥ng tin v√† c√°c ph√¢n t√≠ch c√≥ s·∫µn, c≈©ng nh∆∞ h·ªó tr·ª£ h·ªç ƒë∆∞a ra c√°c quy·∫øt ƒë·ªãnh ch√≠nh x√°c v√† h·ª£p l√Ω d·ª±a tr√™n d·ªØ li·ªáu.

**Th√¥ng tin v·ªÅ b·ªô d·ªØ li·ªáu**:
{dataset_text}

**Nh·∫≠n x√©t t·ª´ con ng∆∞·ªùi**:
{extra_info}
{extra_info_2}

**Ph√¢n t√≠ch v√† nh·∫≠n x√©t t·ª´ OpenAI**:
{openai_insights}

**T√≥m t·∫Øt t·ªïng quan**:
{openai_summary}

**Nhi·ªám v·ª• c·ªßa b·∫°n**:
- X·ª≠ l√Ω v√† ch·ªçn l·ªçc c√°c th√¥ng tin quan tr·ªçng, ƒë·∫∑c bi·ªát ch√∫ tr·ªçng ƒë·∫øn nh·ªØng y·∫øu t·ªë c√≥ t√≠nh tr√πng l·∫∑p cao v√† b·∫£o ƒë·∫£m t√≠nh ch√≠nh x√°c trong c√°c ph√¢n t√≠ch.
- Cung c·∫•p c√°c d·ª± ƒëo√°n ho·∫∑c gi·∫£i th√≠ch d·ª±a tr√™n d·ªØ li·ªáu c√≥ s·∫µn v√† k·∫øt n·ªëi c√°c ph√¢n t√≠ch v·ªõi c√°c t√¨nh hu·ªëng th·ª±c t·∫ø. ƒê·∫£m b·∫£o r·∫±ng c√°c d·ª± ƒëo√°n n√†y d·ªÖ hi·ªÉu v√† c√≥ th·ªÉ gi√∫p ng∆∞·ªùi d√πng h√¨nh dung r√µ r√†ng v·ªÅ k·∫øt qu·∫£ c√≥ th·ªÉ x·∫£y ra.
- Ph√¢n t√≠ch v√† k·∫øt n·ªëi c√°c y·∫øu t·ªë d·ªØ li·ªáu ƒë·ªÉ t·∫°o ra nh·ªØng nh·∫≠n x√©t c√≥ chi·ªÅu s√¢u v√† h·ªØu √≠ch cho ng∆∞·ªùi d√πng. ƒê∆∞a ra c√°c nh·∫≠n x√©t b·ªï sung n·∫øu nh·∫≠n th·∫•y r·∫±ng ng∆∞·ªùi d√πng c√≥ th·ªÉ ch∆∞a nh·∫≠n ra m·ªôt m·ªëi li√™n h·ªá quan tr·ªçng n√†o ƒë√≥ trong d·ªØ li·ªáu.
- Khi tr·∫£ l·ªùi c√¢u h·ªèi, h√£y ƒë·∫£m b·∫£o r·∫±ng c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n r√µ r√†ng, d·ªÖ hi·ªÉu v√† m·∫°ch l·∫°c. ƒê·∫∑c bi·ªát ch√∫ tr·ªçng ƒë·∫øn vi·ªác gi·∫£i quy·∫øt c√°c c√¢u h·ªèi ph·ª©c t·∫°p ho·∫∑c m∆° h·ªì b·∫±ng c√°ch cung c·∫•p c√°c gi·∫£i th√≠ch chi ti·∫øt v√† d·ªÖ ti·∫øp c·∫≠n.
- N·∫øu c√¢u h·ªèi c√≥ s·ª± m∆° h·ªì ho·∫∑c kh√¥ng r√µ r√†ng, h√£y y√™u c·∫ßu ng∆∞·ªùi d√πng cung c·∫•p th√™m th√¥ng tin v√† l√†m r√µ c√°c y√™u c·∫ßu, ho·∫∑c ƒë·ªÅ xu·∫•t c√°c gi·∫£i ph√°p kh·∫£ thi m√† h·ªç c√≥ th·ªÉ tham kh·∫£o ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c c√¢u tr·∫£ l·ªùi ch√≠nh x√°c h∆°n.

**C√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng**: {query}

**C√¢u tr·∫£ l·ªùi m·∫´u t·ª´ OpenAI**: {openai_answer}

H√£y tr·∫£ l·ªùi m·ªôt c√°ch chi ti·∫øt, r√µ r√†ng v√† ch√≠nh x√°c b·∫±ng Ti·∫øng Vi·ªát. ƒê·∫£m b·∫£o r·∫±ng c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n kh√¥ng ch·ªâ ƒë·∫ßy ƒë·ªß m√† c√≤n c√≥ t√≠nh linh ho·∫°t, gi√∫p ng∆∞·ªùi d√πng kh√¥ng ch·ªâ tr·∫£ l·ªùi c√¢u h·ªèi m√† c√≤n kh√°m ph√° th√™m th√¥ng tin c√≥ gi√° tr·ªã t·ª´ b·ªô d·ªØ li·ªáu.
"""
    )
    return generate_openai_response(system_prompt)

if query:
    query_engine = SmartDataframe(
        df,
        config={
            "llm": llm,
            "response_parser": StreamlitResponse,
            #"custom_whitelisted_dependencies": None,
            # "callback": StreamlitCallback(container),
        },
    )
    user_query =  f"""
    **C√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng**: {query}

    H√£y tr·∫£ l·ªùi m·ªôt c√°ch chi ti·∫øt, r√µ r√†ng v√† ch√≠nh x√°c b·∫±ng Ti·∫øng Vi·ªát. ƒê·∫£m b·∫£o r·∫±ng c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n kh√¥ng ch·ªâ ƒë·∫ßy ƒë·ªß m√† c√≤n c√≥ t√≠nh linh ho·∫°t, gi√∫p ng∆∞·ªùi d√πng kh√¥ng ch·ªâ tr·∫£ l·ªùi c√¢u h·ªèi m√† c√≤n kh√°m ph√° th√™m th√¥ng tin c√≥ gi√° tr·ªã t·ª´ b·ªô d·ªØ li·ªáu.
    """

    openai_answer = query_engine.chat(user_query)
    answer = process_user_query(query,openai_answer)
    st.write(answer)